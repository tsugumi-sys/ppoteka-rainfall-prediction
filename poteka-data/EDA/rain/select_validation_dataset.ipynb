{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from common.constants import DATAFOLDER\n",
    "from common.utils import timestep_csv_names\n",
    "\n",
    "data_root_folder_path = DATAFOLDER.data_root_path\n",
    "_timestep_csv_names = timestep_csv_names(delta=10)\n",
    "import json\n",
    "\n",
    "valid_cases = {\n",
    "    \"TC_case\": {\n",
    "        \"sample1\": {\n",
    "            0: {\n",
    "                \"date\": \"2020-10-12\",\n",
    "                \"start\": \"5-0.csv\",\n",
    "            },\n",
    "            1: {\n",
    "                \"date\": \"2020-10-12\",\n",
    "                \"start\": \"6-0.csv\",\n",
    "            },\n",
    "            2: {\n",
    "                \"date\": \"2020-10-12\",\n",
    "                \"start\": \"7-0.csv\",\n",
    "            },\n",
    "            3: {\n",
    "                \"date\": \"2020-10-12\",\n",
    "                \"start\": \"8-0.csv\",\n",
    "            },\n",
    "            4: {\n",
    "                \"date\": \"2020-10-12\",\n",
    "                \"start\": \"9-0.csv\",\n",
    "            },\n",
    "        },\n",
    "        \"sample2\": {\n",
    "            0: {\n",
    "                \"date\": \"2020-09-14\",\n",
    "                \"start\": \"4-0.csv\",\n",
    "            },\n",
    "            1: {\n",
    "                \"date\": \"2020-09-14\",\n",
    "                \"start\": \"5-0.csv\",\n",
    "            },\n",
    "            2: {\n",
    "                \"date\": \"2020-09-14\",\n",
    "                \"start\": \"6-0.csv\",\n",
    "            },\n",
    "        },\n",
    "        \"sample3\": {\n",
    "            0: {\n",
    "                \"date\": \"2020-08-07\",\n",
    "                \"start\": \"4-0.csv\",\n",
    "            },\n",
    "            1: {\n",
    "                \"date\": \"2020-08-07\",\n",
    "                \"start\": \"5-0.csv\",\n",
    "            },\n",
    "            2: {\n",
    "                \"date\": \"2020-08-07\",\n",
    "                \"start\": \"6-0.csv\",\n",
    "            },\n",
    "            3: {\n",
    "                \"date\": \"2020-08-07\",\n",
    "                \"start\": \"7-0.csv\",\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"NOT_TC_case\": {\n",
    "        \"sample1\": {\n",
    "            0: {\n",
    "                \"date\": \"2020-07-04\",\n",
    "                \"start\": \"6-0.csv\",\n",
    "            },\n",
    "            1: {\n",
    "                \"date\": \"2020-07-04\",\n",
    "                \"start\": \"7-0.csv\",\n",
    "            },\n",
    "            2: {\n",
    "                \"date\": \"2020-07-04\",\n",
    "                \"start\": \"8-0.csv\",\n",
    "            },\n",
    "            3: {\n",
    "                \"date\": \"2020-07-04\",\n",
    "                \"start\": \"9-0.csv\",\n",
    "            },\n",
    "            4: {\n",
    "                \"date\": \"2020-07-04\",\n",
    "                \"start\": \"10-0.csv\",\n",
    "            },\n",
    "        },\n",
    "        \"sample2\": {\n",
    "            0: {\n",
    "                \"date\": \"2019-10-04\",\n",
    "                \"start\": \"4-0.csv\",\n",
    "            },\n",
    "            1: {\n",
    "                \"date\": \"2019-10-04\",\n",
    "                \"start\": \"5-0.csv\",\n",
    "            },\n",
    "            2: {\n",
    "                \"date\": \"2019-10-04\",\n",
    "                \"start\": \"6-0.csv\",\n",
    "            },\n",
    "            3: {\n",
    "                \"date\": \"2019-10-04\",\n",
    "                \"start\": \"7-0.csv\",\n",
    "            },\n",
    "        },\n",
    "        \"sample3\": {\n",
    "            0: {\n",
    "                \"date\": \"2019-10-12\",\n",
    "                \"start\": \"8-0.csv\",\n",
    "            },\n",
    "            1: {\n",
    "                \"date\": \"2019-10-12\",\n",
    "                \"start\": \"9-0.csv\",\n",
    "            },\n",
    "            2: {\n",
    "                \"date\": \"2019-10-12\",\n",
    "                \"start\": \"10-0.csv\",\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "_timestep_csv_names = timestep_csv_names(delta=10)\n",
    "dates = {\"TC_case\": [], \"NOT_TC_case\": []}\n",
    "for tc_or_not in valid_cases.keys():\n",
    "    _cases = valid_cases[tc_or_not]\n",
    "    for sample_name in _cases.keys():\n",
    "        count = 0\n",
    "        for senario in _cases[sample_name].keys():\n",
    "            if count == 0:\n",
    "                _date = _cases[sample_name][senario][\"date\"]\n",
    "                dates[tc_or_not].append(_date)\n",
    "                _start_csv_name = _cases[sample_name][senario][\"start\"]\n",
    "                _start_csv_idx = _timestep_csv_names.index(_start_csv_name)\n",
    "            else:\n",
    "                assert _cases[sample_name][senario][\"date\"] == _date\n",
    "                assert _cases[sample_name][senario][\"start\"] == _timestep_csv_names[_start_csv_idx+6]\n",
    "                _start_csv_name = _cases[sample_name][senario][\"start\"]\n",
    "                _start_csv_idx = _timestep_csv_names.index(_start_csv_name)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "path = \"valid_dataset.json\"\n",
    "paths = [\"valid_dataset.json\", \"../../../poteka_pipeline/preprocess/src/valid_dataset.json\"]\n",
    "with open(path, \"w\") as f:\n",
    "    json.dump(valid_cases, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TC_case': ['2020-10-12', '2020-09-14', '2020-08-07'],\n",
       " 'NOT_TC_case': ['2020-07-04', '2019-10-04', '2019-10-12']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-07\n",
      "4-40.csv 5.5\n",
      "4-50.csv 10.5\n",
      "5-0.csv 11.5\n",
      "5-10.csv 18.0\n",
      "5-20.csv 32.0\n",
      "5-30.csv 45.0\n",
      "5-40.csv 61.5\n",
      "5-50.csv 70.0\n",
      "6-0.csv 72.5\n",
      "6-10.csv 59.0\n",
      "6-20.csv 54.0\n",
      "6-30.csv 39.0\n",
      "6-40.csv 26.5\n",
      "6-50.csv 27.0\n",
      "7-0.csv 21.0\n",
      "7-10.csv 14.0\n",
      "7-20.csv 12.5\n",
      "7-30.csv 11.5\n",
      "7-40.csv 7.5\n",
      "7-50.csv 7.5\n",
      "8-0.csv 7.0\n",
      "17-50.csv 6.5\n",
      "18-0.csv 14.5\n",
      "18-10.csv 16.5\n",
      "18-20.csv 16.5\n",
      "18-30.csv 16.5\n",
      "18-40.csv 16.0\n",
      "18-50.csv 13.5\n",
      "19-0.csv 5.5\n"
     ]
    }
   ],
   "source": [
    "date = dates[\"TC_case\"][2]\n",
    "print(date)\n",
    "year, month = date.split(\"-\")[0], date.split(\"-\")[1]\n",
    "\n",
    "for csv_name in _timestep_csv_names:\n",
    "    parquet_filename = csv_name.replace(\".csv\", \".parquet.gzip\")\n",
    "    df = pd.read_parquet(\n",
    "        os.path.join(data_root_folder_path, \"one_day_data\",year, month, date, parquet_filename),\n",
    "        engine=\"pyarrow\",\n",
    "    )\n",
    "    if df[\"hour-rain\"].max() > 5:\n",
    "        print(csv_name, df[\"hour-rain\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-04\n",
      "3-20.csv 8.0\n",
      "3-30.csv 11.5\n",
      "3-40.csv 12.5\n",
      "3-50.csv 12.5\n",
      "4-0.csv 12.5\n",
      "4-10.csv 12.5\n",
      "5-30.csv 19.5\n",
      "5-40.csv 36.5\n",
      "5-50.csv 51.5\n",
      "6-0.csv 60.0\n",
      "6-10.csv 63.5\n",
      "6-20.csv 61.5\n",
      "6-30.csv 45.5\n",
      "6-40.csv 28.5\n",
      "6-50.csv 14.0\n",
      "7-0.csv 14.5\n",
      "7-10.csv 14.5\n",
      "7-20.csv 12.5\n",
      "7-30.csv 12.5\n",
      "7-40.csv 12.5\n",
      "7-50.csv 6.5\n",
      "13-50.csv 20.0\n",
      "14-0.csv 32.5\n",
      "14-10.csv 35.5\n",
      "14-20.csv 38.0\n",
      "14-30.csv 39.5\n",
      "14-40.csv 38.0\n",
      "14-50.csv 20.5\n",
      "15-0.csv 8.0\n",
      "15-10.csv 6.0\n"
     ]
    }
   ],
   "source": [
    "date = dates[\"NOT_TC_case\"][1]\n",
    "print(date)\n",
    "year, month = date.split(\"-\")[0], date.split(\"-\")[1]\n",
    "\n",
    "for csv_name in _timestep_csv_names:\n",
    "    parquet_filename = csv_name.replace(\".csv\", \".parquet.gzip\")\n",
    "    df = pd.read_parquet(\n",
    "        os.path.join(data_root_folder_path, \"one_day_data\",year, month, date, parquet_filename),\n",
    "        engine=\"pyarrow\",\n",
    "    )\n",
    "    if df[\"hour-rain\"].max() > 5:\n",
    "        print(csv_name, df[\"hour-rain\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-40.csv 5.5\n",
      "4-50.csv 10.5\n",
      "5-0.csv 11.5\n",
      "5-10.csv 18.0\n",
      "5-20.csv 32.0\n",
      "5-30.csv 45.0\n",
      "5-40.csv 61.5\n",
      "5-50.csv 70.0\n",
      "6-0.csv 72.5\n",
      "6-10.csv 59.0\n",
      "6-20.csv 54.0\n",
      "6-30.csv 39.0\n",
      "6-40.csv 26.5\n",
      "6-50.csv 27.0\n",
      "7-0.csv 21.0\n",
      "7-10.csv 14.0\n",
      "7-20.csv 12.5\n",
      "7-30.csv 11.5\n",
      "7-40.csv 7.5\n",
      "7-50.csv 7.5\n",
      "8-0.csv 7.0\n",
      "17-50.csv 6.5\n",
      "18-0.csv 14.5\n",
      "18-10.csv 16.5\n",
      "18-20.csv 16.5\n",
      "18-30.csv 16.5\n",
      "18-40.csv 16.0\n",
      "18-50.csv 13.5\n",
      "19-0.csv 5.5\n"
     ]
    }
   ],
   "source": [
    "# TC_case 1\n",
    "case = cases[\"TC_case\"][2]\n",
    "date = case[\"date\"]\n",
    "year, month = date.split(\"-\")[0], date.split(\"-\")[1]\n",
    "\n",
    "for csv_name in _timestep_csv_names:\n",
    "    parquet_filename = csv_name.replace(\".csv\", \".parquet.gzip\")\n",
    "    df = pd.read_parquet(\n",
    "        os.path.join(data_root_folder_path, \"one_day_data\",year, month, date, parquet_filename),\n",
    "        engine=\"pyarrow\",\n",
    "    )\n",
    "    if df[\"hour-rain\"].max() > 5:\n",
    "        print(csv_name, df[\"hour-rain\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0295668de9a873250d44a1e814ff95f1779177595c175aeb6627898987762872"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
